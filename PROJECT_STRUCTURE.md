# Project Structure

## Complete File Structure

```
cookie-collection/
â”œâ”€â”€ README.md                           # Main project documentation
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ setup.py                           # Package installation script
â”œâ”€â”€ LICENSE                            # GPL v3 license
â”œâ”€â”€ .gitignore                         # Git ignore rules
â”œâ”€â”€ PROJECT_STRUCTURE.md               # This file
â”‚
â”œâ”€â”€ src/                               # Source code
â”‚   â”œâ”€â”€ __init__.py                    # Package initialization
â”‚   â”œâ”€â”€ crawlers/                      # Crawler modules
â”‚   â”‚   â”œâ”€â”€ __init__.py               # Crawler package init
â”‚   â”‚   â”œâ”€â”€ shared_utils.py           # Shared utilities
â”‚   â”‚   â”œâ”€â”€ presence_crawler.py       # Fast HTTP-based presence check
â”‚   â”‚   â””â”€â”€ consent_crawler.py        # Browser-based consent crawler
â”‚   â”œâ”€â”€ database/                      # Database processing
â”‚   â”‚   â”œâ”€â”€ __init__.py               # Database package init
â”‚   â”‚   â”œâ”€â”€ extract_cookies.py        # Extract cookies from DB
â”‚   â”‚   â””â”€â”€ post_process.py           # Database cleanup and analysis
â”‚   â””â”€â”€ analysis/                      # Data analysis
â”‚       â”œâ”€â”€ __init__.py               # Analysis package init
â”‚       â””â”€â”€ cookie_stats.py           # Cookie statistics analysis
â”‚
â”œâ”€â”€ scripts/                           # Executable scripts
â”‚   â”œâ”€â”€ run_presence_crawl.py         # Main presence crawler script
â”‚   â”œâ”€â”€ run_consent_crawl.py          # Main consent crawler script
â”‚   â””â”€â”€ run_simple_crawl.py           # Unified simple interface
â”‚
â”œâ”€â”€ config/                            # Configuration files
â”‚   â”œâ”€â”€ crawler_config.py             # Main configuration settings
â”‚   â””â”€â”€ browser_profiles/             # Firefox browser profiles
â”‚       â”œâ”€â”€ accept_all/               # Profile that accepts all cookies
â”‚       â”œâ”€â”€ accept_none/              # Profile that rejects all cookies
â”‚       â””â”€â”€ without_consentomatic/    # Profile without automation
â”‚
â”œâ”€â”€ data/                              # Data directory
â”‚   â”œâ”€â”€ domains/                      # Domain lists
â”‚   â”‚   â””â”€â”€ sample_domains.txt        # Sample domains for testing
â”‚   â”œâ”€â”€ results/                      # Crawler output (created at runtime)
â”‚   â””â”€â”€ examples/                     # Example datasets
â”‚
â”œâ”€â”€ examples/                          # Usage examples
â”‚   â””â”€â”€ basic_crawl.py                # Demonstrates programmatic usage
â”‚
â””â”€â”€ docs/                             # Documentation
    â”œâ”€â”€ installation.md               # Installation instructions
    â””â”€â”€ usage.md                      # Usage guide
```

## Key Features

### ðŸš€ **Simple Installation**
```bash

pip install -e .
```

### âš¡ **Easy Usage**
```bash
# Fast presence check
python scripts/run_presence_crawl.py -n 4 -f data/domains/sample_domains.txt

# Full browser crawl
python scripts/run_consent_crawl.py -n 1 -f data/domains/sample_domains.txt

# Unified interface
python scripts/run_simple_crawl.py -n 4 -f data/domains/sample_domains.txt
```

### ðŸ“Š **Data Analysis**
```bash
# Extract cookies from database
python src/database/extract_cookies.py crawl_data.sqlite

# Analyze cookie statistics  
python src/analysis/cookie_stats.py extracted_cookies.json --summary
```

## Supported CMPs

- **Cookiebot** - Consent platform used by many European sites
- **OneTrust** - Includes OptAnon, CookiePro, and CookieLaw domains
- **Termly** - Privacy management platform

## Output Data

### Presence Crawler
- Categorized domain lists by CMP type
- Connection success/failure reports
- Bot detection responses

### Consent Crawler  
- SQLite database with cookies and consent data
- Structured JSON export for analysis
- Comprehensive crawl statistics

### Analysis Tools
- Cookie name and value pattern analysis
- Security attribute statistics (Secure, HttpOnly, SameSite)
- Purpose category consistency analysis
- CMP comparison reports

## Simplified vs Original

| Aspect | Original | Simplified |
|--------|----------|------------|
| **Size** | ~350 files, 50MB+ | ~25 files, <1MB |
| **Setup** | Complex OpenWPM installation | `pip install -e .` |
| **Dependencies** | Full OpenWPM stack | Essential packages only |
| **Structure** | Research prototype layout | Standard Python package |
| **Documentation** | Scattered README files | Organized docs/ folder |
| **Examples** | Hidden in comments | Clear examples/ directory |
| **Configuration** | Hardcoded in scripts | Centralized config/ |

## What Was Removed

- Full OpenWPM repository (kept only essential functionality)
- Large binary files and sample databases
- Duplicate domain sources and utilities
- Legacy code and unused features
- Development artifacts and logs

## What Was Added

- Standard Python package structure
- Comprehensive documentation
- Working examples
- Centralized configuration
- Clean installation process
- Simplified command-line interface

## Getting Started

1. **Install**: Follow [docs/installation.md](docs/installation.md)
2. **Run Examples**: Try [examples/basic_crawl.py](examples/basic_crawl.py)
3. **Read Usage**: Check [docs/usage.md](docs/usage.md)
4. **Test**: Use [data/domains/sample_domains.txt](data/domains/sample_domains.txt)

## Benefits

âœ… **90% smaller** repository size
âœ… **Professional** Python package structure  
âœ… **Simple** installation and setup
âœ… **Clear** documentation and examples
âœ… **Modular** design for easy extension
âœ… **Standard** development practices
âœ… **Ready** for GitHub and PyPI publication

This simplified version maintains all the core functionality while making it much more accessible and maintainable for research use.
